{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e88d5bf",
   "metadata": {},
   "source": [
    "logit-restricted multiple-choice evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc11874",
   "metadata": {},
   "source": [
    "argmax(logits[\" A\",\" B\",\" C\",\" D\",\" E\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4358d8",
   "metadata": {},
   "source": [
    "# Intervention vectors : \n",
    "    Based on :\n",
    "        *correct-wrong\n",
    "    \n",
    "        *logit gap\n",
    "\n",
    "        *entropy\n",
    "\n",
    "        *tuned-lens-agreement\n",
    "\n",
    "1. individual metrics separetly example large logit gap\n",
    "2. combined vector : q=w1​⋅(logit gap)−w2​⋅entropy+w3​⋅tuned-lens agreement+..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa160e",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca12253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df rows: 4\n",
      "dec_hidden: (4, 13, 128, 768)\n",
      "dec_res_pre_attn: (4, 12, 128, 768)\n",
      "dec_res_post_mlp: (4, 12, 128, 768)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "\n",
    "run_dir = Path(r\"traces\\20251216-193911_gpt2_csqa_validation_n4\")\n",
    "\n",
    "df = pd.read_parquet(run_dir / \"tokens.parquet\")\n",
    "\n",
    "z_hidden = zarr.open(str(run_dir / \"dec_hidden.zarr\"), mode=\"r\")[\"h\"]\n",
    "z_pre = zarr.open(str(run_dir / \"dec_res_pre_attn.zarr\"), mode=\"r\")[\"x\"]\n",
    "z_post_mlp = zarr.open(str(run_dir / \"dec_res_post_mlp.zarr\"), mode=\"r\")[\"x\"]\n",
    "\n",
    "print(\"df rows:\", len(df))\n",
    "print(\"dec_hidden:\", z_hidden.shape)\n",
    "print(\"dec_res_pre_attn:\", z_pre.shape)\n",
    "print(\"dec_res_post_mlp:\", z_post_mlp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6407c887",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parsed only 1 choices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParsed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(choices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m choices\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m question, choices\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m q0, c0 = \u001b[43mparse_csqa_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mquestion[0]:\u001b[39m\u001b[33m\"\u001b[39m, q0[:\u001b[32m120\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mchoices[0]:\u001b[39m\u001b[33m\"\u001b[39m, c0)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mparse_csqa_from_text\u001b[39m\u001b[34m(txt)\u001b[39m\n\u001b[32m     15\u001b[39m         choices[lab] = m.group(\u001b[32m1\u001b[39m).strip()\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(choices) < \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParsed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(choices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m choices\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m question, choices\n",
      "\u001b[31mValueError\u001b[39m: Parsed only 1 choices"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "LABELS = [\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "\n",
    "def parse_csqa_from_text(txt: str):\n",
    "    q = re.search(r\"Q:\\s*(.*?)\\nChoices:\", txt, flags=re.S)\n",
    "    if not q:\n",
    "        raise ValueError(\"Could not parse question\")\n",
    "    question = q.group(1).strip()\n",
    "\n",
    "    choices = {}\n",
    "    for lab in LABELS:\n",
    "        m = re.search(rf\"\\n{lab}:\\s*(.*)\", txt)\n",
    "        if m:\n",
    "            choices[lab] = m.group(1).strip()\n",
    "    if len(choices) < 2:\n",
    "        raise ValueError(f\"Parsed only {len(choices)} choices\")\n",
    "\n",
    "    return question, choices\n",
    "\n",
    "q0, c0 = parse_csqa_from_text(df.loc[0, \"text\"])\n",
    "print(\"question[0]:\", q0[:120], \"...\")\n",
    "print(\"choices[0]:\", c0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc9dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affaecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4f6524a",
   "metadata": {},
   "source": [
    "# Conditional Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991aee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN DIR: C:\\Users\\mikol\\OneDrive\\Pulpit\\Praca Magisterska\\Transformer-Decision-Traces\\traces\\20251216-193911_gpt2_csqa_validation_n4\n",
      "\n",
      "=== meta.json ===\n",
      "{\n",
      "  \"run_id\": \"20251216-193911_gpt2_csqa_validation_n4\",\n",
      "  \"model\": \"gpt2\",\n",
      "  \"arch\": \"dec\",\n",
      "  \"dataset\": \"csqa\",\n",
      "  \"split\": \"validation\",\n",
      "  \"n_examples\": 4,\n",
      "  \"max_seq_len\": 128,\n",
      "  \"num_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"head_dim\": 64,\n",
      "  \"layers_stored\": {\n",
      "    \"enc\": [],\n",
      "    \"dec\": [\n",
      "      0,\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8,\n",
      "      9,\n",
      "      10,\n",
      "      11\n",
      "    ]\n",
      "  },\n",
      "  \"heads_stored\": {\n",
      "    \"enc\": [],\n",
      "    \"dec\": [\n",
      "      0,\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5,\n",
      "      6,\n",
      "      7,\n",
      "      8,\n",
      "      9,\n",
      "      10,\n",
      "      11\n",
      "    ]\n",
      "  },\n",
      "  \"dtype\": \"float16\",\n",
      "  \"capture\": [\n",
      "    \"attn\",\n",
      "    \"qkv\",\n",
      "    \"hidden\",\n",
      "    \"resid\"\n",
      "  ],\n",
      "  \"has_targets\": null,\n",
      "  \"time\": \"2025-12-16 19:39:17\"\n",
      "} ...\n",
      "\n",
      "=== tokens.parquet ===\n",
      "rows: 4 cols: ['example_id', 'text', 'input_ids', 'attention_mask', 'offset_mapping', 'tokens', 'answerKey', 'csqa_choices']\n",
      "                         example_id  \\\n",
      "0  1afa02df02c908a558b4036e80242fac   \n",
      "1  a7ab086045575bb497933726e4e6ad28   \n",
      "\n",
      "                                                text  \n",
      "0  Q: A revolving door is convenient for two dire...  \n",
      "1  Q: What do people aim to do at work?\\nChoices:...  \n",
      "\n",
      "--- example[0] tokens preview ---\n",
      "example_id: 1afa02df02c908a558b4036e80242fac\n",
      "text: Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Choices:\n",
      "A: ...\n",
      "input_ids[:25]: [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256]\n",
      "tokens[:25]: ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>']\n",
      "attention_mask sum: 31\n",
      "\n",
      "--- CSQA column: answerKey ---\n",
      "['A', 'A']\n",
      "\n",
      "--- CSQA column: csqa_choices ---\n",
      "[array([], dtype=object), array([], dtype=object)]\n",
      "\n",
      "=== ZARR stores found ===\n",
      " - dec_hidden.zarr\n",
      " - dec_res_embed.zarr\n",
      " - dec_res_post_attn.zarr\n",
      " - dec_res_post_mlp.zarr\n",
      " - dec_res_pre_attn.zarr\n",
      " - dec_self_attn.zarr\n",
      " - dec_self_qkv.zarr\n",
      "\n",
      "[dec_hidden.zarr] (Group) keys: ['h']\n",
      "  - h: shape=(4, 13, 128, 768), chunks=(1, 1, 128, 768), dtype=float16\n",
      "\n",
      "[dec_res_embed.zarr] (Group) keys: ['x']\n",
      "  - x: shape=(4, 128, 768), chunks=(1, 128, 768), dtype=float16\n",
      "\n",
      "[dec_res_post_attn.zarr] (Group) keys: ['x']\n",
      "  - x: shape=(4, 12, 128, 768), chunks=(1, 1, 128, 768), dtype=float16\n",
      "\n",
      "[dec_res_post_mlp.zarr] (Group) keys: ['x']\n",
      "  - x: shape=(4, 12, 128, 768), chunks=(1, 1, 128, 768), dtype=float16\n",
      "\n",
      "[dec_res_pre_attn.zarr] (Group) keys: ['x']\n",
      "  - x: shape=(4, 12, 128, 768), chunks=(1, 1, 128, 768), dtype=float16\n",
      "\n",
      "[dec_self_attn.zarr] (Group) keys: ['attn']\n",
      "  - attn: shape=(4, 12, 12, 128, 128), chunks=(1, 1, 1, 128, 128), dtype=float16\n",
      "\n",
      "[dec_self_qkv.zarr] (Group) keys: ['k', 'q', 'v']\n",
      "  - k: shape=(4, 12, 12, 128, 64), chunks=(1, 1, 1, 128, 64), dtype=float16\n",
      "  - q: shape=(4, 12, 12, 128, 64), chunks=(1, 1, 1, 128, 64), dtype=float16\n",
      "  - v: shape=(4, 12, 12, 128, 64), chunks=(1, 1, 1, 128, 64), dtype=float16\n",
      "\n",
      "dec_hidden (sample ex0, layer0): shape=(4, 13, 128, 768), dtype=float16\n",
      "  finite%: 100.0\n",
      "  min/mean/max: -122.875 -0.00113677978515625 2400.0\n",
      "  abs-mean: 2.392578125\n",
      "  slice [0,0,:5,:8] = [[ 0.03253  -0.2251    0.05396  -0.03087   0.002148 -0.0725   -0.1871\n",
      "  -0.2554  ]\n",
      " [ 0.0753   -0.0815   -0.04495  -0.0551   -0.0717    0.0636   -0.1732\n",
      "   0.0974  ]\n",
      " [ 0.05557  -0.1124    0.10443  -0.04688  -0.08777   0.04785  -0.1976\n",
      "  -0.02817 ]\n",
      " [ 0.05106  -0.1015    0.1555   -0.04156  -0.0773    0.04324  -0.2128\n",
      "  -0.02747 ]\n",
      " [ 0.059    -0.05276   0.1769   -0.04846  -0.07404   0.05026  -0.215\n",
      "  -0.03528 ]]\n",
      "\n",
      "attn small slice [0,0,0,:5,:5]:\n",
      " [[0.03125 0.      0.      0.      0.     ]\n",
      " [0.0303  0.0303  0.      0.      0.     ]\n",
      " [0.02942 0.02942 0.02942 0.      0.     ]\n",
      " [0.02856 0.02856 0.02856 0.02856 0.     ]\n",
      " [0.02777 0.02777 0.02777 0.02777 0.02777]]\n",
      "row_sums (should be ~1.0 if not masked in this slice): [0.03125 0.0606  0.08826 0.11426 0.1389 ]\n",
      "\n",
      "q (ex0, layer0, head0, first 5 tokens, first 8 dims): shape=(5, 8), dtype=float16\n",
      "  finite%: 100.0\n",
      "  min/mean/max: -1.13671875 0.0235137939453125 1.1435546875\n",
      "  abs-mean: 0.6806640625\n",
      "\n",
      "k (ex0, layer0, head0, first 5 tokens, first 8 dims): shape=(5, 8), dtype=float16\n",
      "  finite%: 100.0\n",
      "  min/mean/max: -1.2529296875 0.2174072265625 2.59765625\n",
      "  abs-mean: 0.8095703125\n",
      "\n",
      "v (ex0, layer0, head0, first 5 tokens, first 8 dims): shape=(5, 8), dtype=float16\n",
      "  finite%: 100.0\n",
      "  min/mean/max: -0.23193359375 0.08465576171875 0.29052734375\n",
      "  abs-mean: 0.139404296875\n",
      "\n",
      "=== dec_res_embed.zarr tiny slice ===\n",
      "shape: (4, 128, 768) dtype: float16\n",
      "ex0 slice: [[ 0.05136 -0.0277   0.04993 -0.0422  -0.06168  0.03253 -0.2241  -0.0874 ]\n",
      " [ 0.05136 -0.0277   0.04993 -0.0422  -0.06168  0.03253 -0.2241  -0.0874 ]\n",
      " [ 0.05136 -0.0277   0.04993 -0.0422  -0.06168  0.03253 -0.2241  -0.0874 ]\n",
      " [ 0.05136 -0.0277   0.04993 -0.0422  -0.06168  0.03253 -0.2241  -0.0874 ]\n",
      " [ 0.05136 -0.0277   0.04993 -0.0422  -0.06168  0.03253 -0.2241  -0.0874 ]]\n",
      "\n",
      "=== dec_res_pre_attn.zarr tiny slice ===\n",
      "shape: (4, 12, 128, 768) dtype: float16\n",
      "ex0 slice: [[ 0.03253  -0.2251    0.05396  -0.03087   0.002148 -0.0725   -0.1871\n",
      "  -0.2554  ]\n",
      " [ 0.0753   -0.0815   -0.04495  -0.0551   -0.0717    0.0636   -0.1732\n",
      "   0.0974  ]\n",
      " [ 0.05557  -0.1124    0.10443  -0.04688  -0.08777   0.04785  -0.1976\n",
      "  -0.02817 ]\n",
      " [ 0.05106  -0.1015    0.1555   -0.04156  -0.0773    0.04324  -0.2128\n",
      "  -0.02747 ]\n",
      " [ 0.059    -0.05276   0.1769   -0.04846  -0.07404   0.05026  -0.215\n",
      "  -0.03528 ]]\n",
      "\n",
      "=== dec_res_post_attn.zarr tiny slice ===\n",
      "shape: (4, 12, 128, 768) dtype: float16\n",
      "ex0 slice: [[-1.8823e-01 -2.0142e-03  3.0396e-01 -8.2825e-02 -9.5139e-03 -9.6313e-02\n",
      "   3.2227e-01 -4.1133e+00]\n",
      " [-1.1212e-01  1.4001e-01  1.8652e-01 -1.0870e-01 -8.1848e-02  3.6865e-02\n",
      "   3.3862e-01 -3.5684e+00]\n",
      " [-9.6802e-02  1.1353e-01  3.2300e-01 -1.0181e-01 -9.5764e-02  1.7563e-02\n",
      "   3.3350e-01 -3.5508e+00]\n",
      " [-6.5186e-02  1.2976e-01  3.6230e-01 -9.7900e-02 -8.2825e-02  9.5215e-03\n",
      "   3.3862e-01 -3.4277e+00]\n",
      " [-2.0264e-02  1.8335e-01  3.7231e-01 -1.0596e-01 -7.6965e-02  1.3062e-02\n",
      "   3.5596e-01 -3.3242e+00]]\n",
      "\n",
      "=== dec_res_post_mlp.zarr tiny slice ===\n",
      "shape: (4, 12, 128, 768) dtype: float16\n",
      "ex0 slice: [[-7.5098e-01  4.2105e-04  1.2373e+00 -5.3192e-02  3.0518e-01 -1.4316e+00\n",
      "   3.4414e+00 -1.6602e+00]\n",
      " [ 1.2512e-01  5.2795e-03  1.0127e+00 -4.4751e-01  1.8115e-01 -4.6606e-01\n",
      "   3.6250e+00 -8.4717e-01]\n",
      " [ 1.1902e-01 -1.0370e-01  1.2422e+00 -6.1426e-01  7.3547e-02 -4.2236e-01\n",
      "   3.8516e+00 -8.1006e-01]\n",
      " [ 2.0264e-01 -4.3732e-02  1.3262e+00 -5.8252e-01  1.1707e-01 -4.6948e-01\n",
      "   3.9707e+00 -9.1260e-01]\n",
      " [ 2.3145e-01 -2.9354e-03  1.3682e+00 -5.6250e-01  1.7822e-01 -5.1807e-01\n",
      "   3.9883e+00 -9.9121e-01]]\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "\n",
    "run_dir = Path(r\"traces\\20251216-193911_gpt2_csqa_validation_n4\")\n",
    "\n",
    "print(\"RUN DIR:\", run_dir.resolve())\n",
    "assert run_dir.exists(), f\"Not found: {run_dir}\"\n",
    "\n",
    "meta_path = run_dir / \"meta.json\"\n",
    "print(\"\\n=== meta.json ===\")\n",
    "with meta_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "print(json.dumps(meta, indent=2)[:2000], \"...\\n\")\n",
    "\n",
    "tok_path = run_dir / \"tokens.parquet\"\n",
    "print(\"=== tokens.parquet ===\")\n",
    "df = pd.read_parquet(tok_path)\n",
    "print(\"rows:\", len(df), \"cols:\", list(df.columns))\n",
    "print(df.head(2)[[\"example_id\", \"text\"]])\n",
    "\n",
    "i = 0\n",
    "print(\"\\n--- example[0] tokens preview ---\")\n",
    "print(\"example_id:\", df.loc[i, \"example_id\"])\n",
    "print(\"text:\", df.loc[i, \"text\"][:200], \"...\")\n",
    "print(\"input_ids[:25]:\", df.loc[i, \"input_ids\"][:25])\n",
    "print(\"tokens[:25]:\", df.loc[i, \"tokens\"][:25])\n",
    "print(\"attention_mask sum:\", int(np.sum(df.loc[i, \"attention_mask\"])))\n",
    "\n",
    "for col in [\"answerKey\", \"csqa_choices\"]:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n--- CSQA column: {col} ---\")\n",
    "        print(df[col].head(2).tolist())\n",
    "\n",
    "def describe_zarr_store(store_path: Path):\n",
    "    root = zarr.open(str(store_path), mode=\"r\")\n",
    "    if isinstance(root, zarr.hierarchy.Group):\n",
    "        print(f\"\\n[{store_path.name}] (Group) keys:\", list(root.array_keys()))\n",
    "        for k in root.array_keys():\n",
    "            arr = root[k]\n",
    "            print(f\"  - {k}: shape={arr.shape}, chunks={arr.chunks}, dtype={arr.dtype}\")\n",
    "    else:\n",
    "        arr = root\n",
    "        print(f\"\\n[{store_path.name}] (Array) shape={arr.shape}, chunks={arr.chunks}, dtype={arr.dtype}\")\n",
    "\n",
    "def get_array_from_store(store_path: Path, key: str):\n",
    "    root = zarr.open(str(store_path), mode=\"r\")\n",
    "    if isinstance(root, zarr.hierarchy.Group):\n",
    "        return root[key]\n",
    "    return root  # array store\n",
    "\n",
    "zarr_paths = sorted(run_dir.glob(\"*.zarr\"))\n",
    "print(\"\\n=== ZARR stores found ===\")\n",
    "for p in zarr_paths:\n",
    "    print(\" -\", p.name)\n",
    "\n",
    "for p in zarr_paths:\n",
    "    describe_zarr_store(p)\n",
    "9\n",
    "def quick_stats(arr, name, slc=None):\n",
    "    x = arr[:] if slc is None else arr[slc]\n",
    "    x = np.asarray(x)\n",
    "    finite = np.isfinite(x)\n",
    "    print(f\"\\n{name}: shape={x.shape}, dtype={x.dtype}\")\n",
    "    print(\"  finite%:\", float(finite.mean()) * 100.0)\n",
    "    if finite.any():\n",
    "        xf = x[finite]\n",
    "        print(\"  min/mean/max:\", float(xf.min()), float(xf.mean()), float(xf.max()))\n",
    "        print(\"  abs-mean:\", float(np.abs(xf).mean()))\n",
    "    else:\n",
    "        print(\"  all non-finite (bad)\")\n",
    "\n",
    "\n",
    "if (run_dir / \"dec_hidden.zarr\").exists():\n",
    "    arr = get_array_from_store(run_dir / \"dec_hidden.zarr\", \"h\")\n",
    "    quick_stats(arr, \"dec_hidden (sample ex0, layer0)\")\n",
    "    # ex0, layer0, first 5 tokens, first 8 dims\n",
    "    print(\"  slice [0,0,:5,:8] =\", np.asarray(arr[0,0,:5,:8]))\n",
    "\n",
    "# 2) attentions\n",
    "if (run_dir / \"dec_self_attn.zarr\").exists():\n",
    "    arr = get_array_from_store(run_dir / \"dec_self_attn.zarr\", \"attn\")\n",
    "    x = np.asarray(arr[0,0,0,:5,:5])  # ex0, layer0, head0, first 5x5\n",
    "    print(\"\\nattn small slice [0,0,0,:5,:5]:\\n\", x)\n",
    "    row_sums = x.sum(axis=-1)\n",
    "    print(\"row_sums (should be ~1.0 if not masked in this slice):\", row_sums)\n",
    "\n",
    "# 3) QKV\n",
    "if (run_dir / \"dec_self_qkv.zarr\").exists():\n",
    "    q = get_array_from_store(run_dir / \"dec_self_qkv.zarr\", \"q\")\n",
    "    k = get_array_from_store(run_dir / \"dec_self_qkv.zarr\", \"k\")\n",
    "    v = get_array_from_store(run_dir / \"dec_self_qkv.zarr\", \"v\")\n",
    "    quick_stats(q, \"q (ex0, layer0, head0, first 5 tokens, first 8 dims)\", slc=(0,0,0,slice(0,5),slice(0,8)))\n",
    "    quick_stats(k, \"k (ex0, layer0, head0, first 5 tokens, first 8 dims)\", slc=(0,0,0,slice(0,5),slice(0,8)))\n",
    "    quick_stats(v, \"v (ex0, layer0, head0, first 5 tokens, first 8 dims)\", slc=(0,0,0,slice(0,5),slice(0,8)))\n",
    "\n",
    "# 4) Residual checkpoints\n",
    "for nm, key in [\n",
    "    (\"dec_res_embed.zarr\", \"x\"),\n",
    "    (\"dec_res_pre_attn.zarr\", \"x\"),\n",
    "    (\"dec_res_post_attn.zarr\", \"x\"),\n",
    "    (\"dec_res_post_mlp.zarr\", \"x\"),\n",
    "]:\n",
    "    p = run_dir / nm\n",
    "    if p.exists():\n",
    "        arr = get_array_from_store(p, key)\n",
    "        print(f\"\\n=== {nm} tiny slice ===\")\n",
    "        print(\"shape:\", arr.shape, \"dtype:\", arr.dtype)\n",
    "        print(\"ex0 slice:\", np.asarray(arr[0, :5, :8]) if arr.ndim == 3 else np.asarray(arr[0, 0, :5, :8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN DIR: C:\\Users\\mikol\\OneDrive\\Pulpit\\Praca Magisterska\\Transformer-Decision-Traces\\traces\\20251216-193911_gpt2_csqa_validation_n4\n",
      "\n",
      "=== meta.json (key fields) ===\n",
      "{'run_id': '20251216-193911_gpt2_csqa_validation_n4', 'model': 'gpt2', 'arch': 'dec', 'dataset': 'csqa', 'split': 'validation', 'n_examples': 4, 'max_seq_len': 128, 'num_layers': 12, 'num_heads': 12, 'head_dim': 64, 'dtype': 'float16', 'capture': ['attn', 'qkv', 'hidden', 'resid']}\n",
      "\n",
      "=== tokens.parquet ===\n",
      "rows: 4 cols: ['example_id', 'text', 'input_ids', 'attention_mask', 'offset_mapping', 'tokens', 'answerKey', 'csqa_choices']\n",
      "\n",
      "=== ZARR SHAPES ===\n",
      "attn: (4, 12, 12, 128, 128) float16\n",
      "Q: (4, 12, 12, 128, 64) float16 | K: (4, 12, 12, 128, 64) | V: (4, 12, 12, 128, 64)\n",
      "pre: (4, 12, 128, 768) float16 | post: (4, 12, 128, 768) float16\n",
      "\n",
      "LETTER_IDS: {'A': [32, 317], 'B': [33, 347], 'C': [34, 327], 'D': [35, 360], 'E': [36, 412]}\n",
      "\n",
      "=== TEXT DEBUG (repr preview) ===\n",
      "'Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\\nChoices:\\nA:'\n",
      "\n",
      "=== TEXT DEBUG (tail) ===\n",
      "Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "=== ATTENTION-TO-OPTIONS SUMMARY ===\n",
      "   i                        example_id gold attn_pick  attn_gold  attn_pred  \\\n",
      "0  0  1afa02df02c908a558b4036e80242fac    A      None        NaN        NaN   \n",
      "1  1  a7ab086045575bb497933726e4e6ad28    A      None        NaN        NaN   \n",
      "2  2  b8c0a4703079cf661d7261a60a1bcbff    B      None        NaN        NaN   \n",
      "3  3  e68fb2448fd74e402aae9982aa76e527    A      None        NaN        NaN   \n",
      "\n",
      "   pre_norm_meanL  post_norm_meanL  choices_parsed  \n",
      "0       93.713203       121.760925               0  \n",
      "1       97.401878       127.399544               0  \n",
      "2       95.621223       123.664879               0  \n",
      "3       95.065491       125.114716               0  \n",
      "\n",
      "choices_parsed distribution:\n",
      "choices_parsed\n",
      "0    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[RED FLAG] choices_parsed is 0 for all examples -> your prompt format doesn't match the parser.\n",
      "Check repr(text) output above. If you see '\\\\n' everywhere, your dataset has escaped newlines.\n",
      "If options are like 'A -' or 'A)' without space, tweak the regex in find_choice_char_spans().\n",
      "\n",
      "(attn_pred - attn_gold) per example:\n",
      "[nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "import os, json, re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "\n",
    "RUN_DIR = r\"C:\\Users\\mikol\\OneDrive\\Pulpit\\Praca Magisterska\\Transformer-Decision-Traces\\traces\\20251216-193911_gpt2_csqa_validation_n4\"\n",
    "\n",
    "run = Path(RUN_DIR)\n",
    "meta = json.loads((run / \"meta.json\").read_text(encoding=\"utf-8\"))\n",
    "df = pd.read_parquet(run / \"tokens.parquet\")\n",
    "\n",
    "print(\"RUN DIR:\", run)\n",
    "print(\"\\n=== meta.json (key fields) ===\")\n",
    "print({k: meta[k] for k in [\"run_id\",\"model\",\"arch\",\"dataset\",\"split\",\"n_examples\",\"max_seq_len\",\"num_layers\",\"num_heads\",\"head_dim\",\"dtype\",\"capture\"]})\n",
    "print(\"\\n=== tokens.parquet ===\")\n",
    "print(\"rows:\", len(df), \"cols:\", list(df.columns))\n",
    "\n",
    "# OPEN ZARR STORES\n",
    "attn = zarr.open(str(run / \"dec_self_attn.zarr\"), mode=\"r\")[\"attn\"]      # (N,L,H,T,T)\n",
    "qkv  = zarr.open(str(run / \"dec_self_qkv.zarr\"),  mode=\"r\")\n",
    "Q = qkv[\"q\"]; K = qkv[\"k\"]; V = qkv[\"v\"]                                 # (N,L,H,T,d)\n",
    "pre  = zarr.open(str(run / \"dec_res_pre_attn.zarr\"),  mode=\"r\")[\"x\"]      # (N,L,T,D)\n",
    "post = zarr.open(str(run / \"dec_res_post_attn.zarr\"), mode=\"r\")[\"x\"]      # (N,L,T,D)\n",
    "\n",
    "print(\"\\n=== ZARR SHAPES ===\")\n",
    "print(\"attn:\", attn.shape, attn.dtype)\n",
    "print(\"Q:\", Q.shape, Q.dtype, \"| K:\", K.shape, \"| V:\", V.shape)\n",
    "print(\"pre:\", pre.shape, pre.dtype, \"| post:\", post.shape, post.dtype)\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x = x.astype(np.float64)  # stability\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    ex = np.exp(x)\n",
    "    return ex / np.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "def find_choice_char_spans(text: str):\n",
    "    txt = text.replace(\"\\\\n\", \"\\n\").replace(\"\\r\\n\", \"\\n\")\n",
    "\n",
    "    pat = re.compile(r\"(?:^|\\n)\\s*([A-E])\\s*[:\\)\\.]\\s*\")\n",
    "    matches = list(pat.finditer(txt))\n",
    "    if len(matches) < 2:\n",
    "        return {}\n",
    "\n",
    "    spans = {}\n",
    "    for j, m in enumerate(matches):\n",
    "        L = m.group(1)\n",
    "        start = m.end()\n",
    "        end = matches[j + 1].start() if j + 1 < len(matches) else len(txt)\n",
    "        spans[L] = (start, end)\n",
    "    return spans\n",
    "\n",
    "def charspan_to_token_idxs(offset_mapping, char_span):\n",
    "    a, b = char_span\n",
    "    idxs = []\n",
    "    for t, (s, e) in enumerate(offset_mapping):\n",
    "        if s == 0 and e == 0:\n",
    "            continue\n",
    "        if e <= a:\n",
    "            continue\n",
    "        if s >= b:\n",
    "            break\n",
    "        if max(s, a) < min(e, b):\n",
    "            idxs.append(t)\n",
    "    return idxs\n",
    "\n",
    "LETTER_IDS = {\n",
    "    \"A\": [32, 317],\n",
    "    \"B\": [33, 347],\n",
    "    \"C\": [34, 327],\n",
    "    \"D\": [35, 360],\n",
    "    \"E\": [36, 412],\n",
    "}\n",
    "print(\"\\nLETTER_IDS:\", LETTER_IDS)\n",
    "\n",
    "def predict_letter_from_logits(last_logits):\n",
    "    p = softmax(last_logits, axis=-1)\n",
    "    letter_probs = {}\n",
    "    for L, ids in LETTER_IDS.items():\n",
    "        ids = [i for i in ids if i < p.shape[0]]\n",
    "        letter_probs[L] = float(np.max(p[ids])) if ids else float(\"nan\")\n",
    "    pred = max(letter_probs, key=lambda k: letter_probs[k])\n",
    "    return pred, letter_probs[pred], letter_probs\n",
    "\n",
    "\n",
    "print(\"\\n=== TEXT DEBUG (repr preview) ===\")\n",
    "print(repr(df.loc[0, \"text\"][:400]))\n",
    "print(\"\\n=== TEXT DEBUG (tail) ===\")\n",
    "print(df.loc[0, \"text\"][-200:])\n",
    "\n",
    "rows = []\n",
    "for i in range(len(df)):\n",
    "    text = df.loc[i, \"text\"]\n",
    "    gold = df.loc[i, \"answerKey\"] if \"answerKey\" in df.columns else None\n",
    "\n",
    "    input_ids = np.array(df.loc[i, \"input_ids\"], dtype=np.int64)\n",
    "    attn_mask = np.array(df.loc[i, \"attention_mask\"], dtype=np.int64)\n",
    "    offsets   = df.loc[i, \"offset_mapping\"]\n",
    "\n",
    "    # last non-pad position (for left padding, this is last token where mask=1)\n",
    "    last = int(np.where(attn_mask == 1)[0][-1])\n",
    "\n",
    "    # option spans \n",
    "    spans = find_choice_char_spans(text)\n",
    "    token_spans = {L: charspan_to_token_idxs(offsets, sp) for L, sp in spans.items()}\n",
    "    choices_parsed = sum(1 for L in \"ABCDE\" if L in token_spans and len(token_spans[L]) > 0)\n",
    "\n",
    "    # attention tensor: mean over layers/heads at \"query token = last\"\n",
    "    # attn[i] shape (L,H,T,T) ; take [:,:,last,:] -> (L,H,T)\n",
    "    A = np.asarray(attn[i, :, :, last, :], dtype=np.float32)\n",
    "    A_mean = A.mean(axis=(0, 1))  # (T,)\n",
    "\n",
    "    attn_mass = {}\n",
    "    for L in \"ABCDE\":\n",
    "        toks = token_spans.get(L, [])\n",
    "        attn_mass[L] = float(A_mean[toks].sum()) if toks else float(\"nan\")\n",
    "\n",
    "    # best attention-picked letter\n",
    "    attn_pick = None\n",
    "    if any(np.isfinite(attn_mass[L]) for L in \"ABCDE\"):\n",
    "        attn_pick = max(\"ABCDE\", key=lambda L: (attn_mass[L] if np.isfinite(attn_mass[L]) else -1e9))\n",
    "\n",
    "    # residual norms (cast to float32 to avoid overflow)\n",
    "    pre_i  = np.asarray(pre[i], dtype=np.float32)   # (L,T,D)\n",
    "    post_i = np.asarray(post[i], dtype=np.float32)\n",
    "    pre_norm_meanL  = float(np.linalg.norm(pre_i[:, last, :],  axis=-1).mean())\n",
    "    post_norm_meanL = float(np.linalg.norm(post_i[:, last, :], axis=-1).mean())\n",
    "\n",
    "    rows.append({\n",
    "        \"i\": i,\n",
    "        \"example_id\": df.loc[i, \"example_id\"],\n",
    "        \"gold\": gold,\n",
    "        \"attn_pick\": attn_pick,\n",
    "        \"attn_gold\": attn_mass.get(gold, float(\"nan\")) if gold else float(\"nan\"),\n",
    "        \"attn_pred\": attn_mass.get(attn_pick, float(\"nan\")) if attn_pick else float(\"nan\"),\n",
    "        \"pre_norm_meanL\": pre_norm_meanL,\n",
    "        \"post_norm_meanL\": post_norm_meanL,\n",
    "        \"choices_parsed\": choices_parsed,\n",
    "    })\n",
    "\n",
    "res = pd.DataFrame(rows)\n",
    "\n",
    "print(\"\\n=== ATTENTION-TO-OPTIONS SUMMARY ===\")\n",
    "print(res)\n",
    "\n",
    "# diagnostics\n",
    "print(\"\\nchoices_parsed distribution:\")\n",
    "print(res[\"choices_parsed\"].value_counts(dropna=False))\n",
    "\n",
    "if res[\"choices_parsed\"].max() == 0:\n",
    "    print(\"\\n[RED FLAG] choices_parsed is 0 for all examples e.g. prompt format doesn't match the parser.\")\n",
    "\n",
    "# difference metric \n",
    "valid = res[np.isfinite(res[\"attn_gold\"]) & np.isfinite(res[\"attn_pred\"])]\n",
    "if len(valid) > 0:\n",
    "    diffs = (valid[\"attn_pred\"] - valid[\"attn_gold\"]).to_list()\n",
    "    print(\"\\n(attn_pred - attn_gold) per valid example:\")\n",
    "    print(diffs)\n",
    "else:\n",
    "    print(\"\\n(attn_pred - attn_gold) per example:\")\n",
    "    print([float(\"nan\")] * len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e97840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['example_id', 'text', 'answerKey', 'correct_idx', 'csqa_choices']\n",
      "\n",
      "--- Prompt preview ---\n",
      "Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Choices:\n",
      "A: bank\n",
      "B: library\n",
      "C: department store\n",
      "D: mall\n",
      "E: new york\n",
      "Answer:\n",
      "\n",
      "answerKey: A correct_idx: 0\n",
      "csqa_choices type: <class 'list'>\n",
      "csqa_choices len: 5\n",
      "csqa_choices[0]: {'label': 'A', 'text': 'bank'}\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_csqa import load_csqa\n",
    "\n",
    "df = load_csqa(split=\"validation\", limit=2)\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\n--- Prompt preview ---\")\n",
    "print(df.loc[0, \"text\"][:400])\n",
    "\n",
    "print(\"\\nanswerKey:\", df.loc[0, \"answerKey\"], \"correct_idx:\", df.loc[0, \"correct_idx\"])\n",
    "print(\"csqa_choices type:\", type(df.loc[0, \"csqa_choices\"]))\n",
    "print(\"csqa_choices len:\", len(df.loc[0, \"csqa_choices\"]))\n",
    "print(\"csqa_choices[0]:\", df.loc[0, \"csqa_choices\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1477e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\venvs\\Masters_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf keys: dict_keys(['id', 'question', 'question_concept', 'choices', 'answerKey'])\n",
      "id: 1afa02df02c908a558b4036e80242fac\n",
      "question: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "choices labels: ['A', 'B', 'C', 'D', 'E']\n",
      "choices texts head: ['bank', 'library', 'department store', 'mall', 'new york']\n",
      "answerKey: A\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "ds = load_dataset(\"commonsense_qa\", split=\"validation\")\n",
    "\n",
    "ex = ds[0]\n",
    "print(\"hf keys:\", ex.keys())\n",
    "print(\"id:\", ex[\"id\"])\n",
    "print(\"question:\", ex[\"question\"][:120])\n",
    "print(\"choices labels:\", ex[\"choices\"][\"label\"])\n",
    "print(\"choices texts head:\", [t[:25] for t in ex[\"choices\"][\"text\"]])\n",
    "print(\"answerKey:\", ex[\"answerKey\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters_env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
