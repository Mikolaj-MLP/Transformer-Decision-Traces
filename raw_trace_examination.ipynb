{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0478a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15870a1",
   "metadata": {},
   "source": [
    "*******************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f85d70",
   "metadata": {},
   "source": [
    "***Notebook aimend at viewing the raw data structure***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798dc0e",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7394bd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta keys: ['run_id', 'model', 'arch', 'dataset', 'split', 'n_examples', 'max_seq_len', 'num_layers', 'num_heads', 'head_dim', 'layers_stored', 'heads_stored', 'dtype', 'capture', 'has_targets', 'time']\n",
      "model: gpt2 dataset: csqa split: validation\n",
      "n_examples: 4 max_seq_len: 128\n",
      "num_layers: 12 num_heads: 12 dtype: float16\n",
      "capture: ['attn', 'qkv', 'hidden', 'resid']\n"
     ]
    }
   ],
   "source": [
    "run_dir = Path(r\"traces\\20251216-193911_gpt2_csqa_validation_n4\")\n",
    "\n",
    "meta = json.loads((run_dir / \"meta.json\").read_text(encoding=\"utf-8\"))\n",
    "print(\"meta keys:\", list(meta.keys()))\n",
    "print(\"model:\", meta.get(\"model\"), \"dataset:\", meta.get(\"dataset\"), \"split:\", meta.get(\"split\"))\n",
    "print(\"n_examples:\", meta.get(\"n_examples\"), \"max_seq_len:\", meta.get(\"max_seq_len\"))\n",
    "print(\"num_layers:\", meta.get(\"num_layers\"), \"num_heads:\", meta.get(\"num_heads\"), \"dtype:\", meta.get(\"dtype\"))\n",
    "print(\"capture:\", meta.get(\"capture\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c606bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 4\n",
      "cols: ['example_id', 'text', 'input_ids', 'attention_mask', 'offset_mapping', 'tokens', 'answerKey', 'csqa_choices']\n",
      "                         example_id answerKey\n",
      "0  1afa02df02c908a558b4036e80242fac         A\n",
      "1  a7ab086045575bb497933726e4e6ad28         A\n",
      "2  b8c0a4703079cf661d7261a60a1bcbff         B\n",
      "3  e68fb2448fd74e402aae9982aa76e527         A\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(run_dir / \"tokens.parquet\")\n",
    "print(\"rows:\", len(df))\n",
    "print(\"cols:\", list(df.columns))\n",
    "print(df.head(4)[[\"example_id\", \"answerKey\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e804837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IDX: 0 example_id: 1afa02df02c908a558b4036e80242fac\n",
      "text len: 123\n",
      "text repr head: 'Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "IDX: 1 example_id: a7ab086045575bb497933726e4e6ad28\n",
      "text len: 48\n",
      "text repr head: 'Q: What do people aim to do at work?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: What do people aim to do at work?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "IDX: 2 example_id: b8c0a4703079cf661d7261a60a1bcbff\n",
      "text len: 82\n",
      "text repr head: 'Q: Where would you find magazines along side many other printed works?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: Where would you find magazines along side many other printed works?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "IDX: 3 example_id: e68fb2448fd74e402aae9982aa76e527\n",
      "text len: 57\n",
      "text repr head: 'Q: Where are  you likely to find a hamburger?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: Where are  you likely to find a hamburger?\n",
      "Choices:\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 400)\n",
    "for i in range(min(4, len(df))):\n",
    "    txt = df.loc[i, \"text\"]\n",
    "    print(\"\\nIDX:\", i, \"example_id:\", df.loc[i, \"example_id\"])\n",
    "    print(\"text len:\", len(txt))\n",
    "    print(\"text repr head:\", repr(txt[:250]))\n",
    "    print(\"text head:\\n\", txt[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "711a52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IDX: 0 example_id: 1afa02df02c908a558b4036e80242fac\n",
      "text len: 123\n",
      "text repr head: 'Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "IDX: 1 example_id: a7ab086045575bb497933726e4e6ad28\n",
      "text len: 48\n",
      "text repr head: 'Q: What do people aim to do at work?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: What do people aim to do at work?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "IDX: 2 example_id: b8c0a4703079cf661d7261a60a1bcbff\n",
      "text len: 82\n",
      "text repr head: 'Q: Where would you find magazines along side many other printed works?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: Where would you find magazines along side many other printed works?\n",
      "Choices:\n",
      "A:\n",
      "\n",
      "IDX: 3 example_id: e68fb2448fd74e402aae9982aa76e527\n",
      "text len: 57\n",
      "text repr head: 'Q: Where are  you likely to find a hamburger?\\nChoices:\\nA:'\n",
      "text head:\n",
      " Q: Where are  you likely to find a hamburger?\n",
      "Choices:\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 400)\n",
    "for i in range(min(4, len(df))):\n",
    "    txt = df.loc[i, \"text\"]\n",
    "    print(\"\\nIDX:\", i, \"example_id:\", df.loc[i, \"example_id\"])\n",
    "    print(\"text len:\", len(txt))\n",
    "    print(\"text repr head:\", repr(txt[:250]))\n",
    "    print(\"text head:\\n\", txt[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742b5ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IDX: 0\n",
      "types: <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "len tokens: 128 len ids: 128 len mask: 128\n",
      "mask sum: 31\n",
      "first 40 tokens: ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>']\n",
      "first 40 ids: [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256]\n",
      "last 40 tokens (active): ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>']\n",
      "last 40 ids (active): [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256]\n",
      "\n",
      "IDX: 1\n",
      "types: <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "len tokens: 128 len ids: 128 len mask: 128\n",
      "mask sum: 18\n",
      "first 40 tokens: ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>']\n",
      "first 40 ids: [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256]\n",
      "last 40 tokens (active): ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>']\n",
      "last 40 ids (active): [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256]\n",
      "\n",
      "IDX: 2\n",
      "types: <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "len tokens: 128 len ids: 128 len mask: 128\n",
      "mask sum: 21\n",
      "first 40 tokens: ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>']\n",
      "first 40 ids: [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256]\n",
      "last 40 tokens (active): ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>']\n",
      "last 40 ids (active): [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256]\n",
      "\n",
      "IDX: 3\n",
      "types: <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "len tokens: 128 len ids: 128 len mask: 128\n",
      "mask sum: 20\n",
      "first 40 tokens: ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>']\n",
      "first 40 ids: [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256]\n",
      "last 40 tokens (active): ['<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>'\n",
      " '<|endoftext|>' '<|endoftext|>' '<|endoftext|>' '<|endoftext|>']\n",
      "last 40 ids (active): [50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256]\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(4, len(df))):\n",
    "    toks = df.loc[i, \"tokens\"]\n",
    "    ids = df.loc[i, \"input_ids\"]\n",
    "    am = df.loc[i, \"attention_mask\"]\n",
    "    print(\"\\nIDX:\", i)\n",
    "    print(\"types:\", type(toks), type(ids), type(am))\n",
    "    print(\"len tokens:\", len(toks), \"len ids:\", len(ids), \"len mask:\", len(am))\n",
    "    print(\"mask sum:\", int(np.sum(am)))\n",
    "    print(\"first 40 tokens:\", toks[:40])\n",
    "    print(\"first 40 ids:\", ids[:40])\n",
    "    k = int(np.sum(am))\n",
    "    print(\"last 40 tokens (active):\", toks[max(0, k-40):k])\n",
    "    print(\"last 40 ids (active):\", ids[max(0, k-40):k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5c5483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarr stores: ['dec_hidden.zarr', 'dec_res_embed.zarr', 'dec_res_post_attn.zarr', 'dec_res_post_mlp.zarr', 'dec_res_pre_attn.zarr', 'dec_self_attn.zarr', 'dec_self_qkv.zarr']\n"
     ]
    }
   ],
   "source": [
    "zarr_paths = sorted(run_dir.glob(\"*.zarr\"))\n",
    "print(\"zarr stores:\", [p.name for p in zarr_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a15a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dec_hidden.zarr keys: ['h']\n",
      "  h shape (4, 13, 128, 768) chunks (1, 1, 128, 768) dtype float16\n",
      "\n",
      " dec_res_embed.zarr keys: ['x']\n",
      "  x shape (4, 128, 768) chunks (1, 128, 768) dtype float16\n",
      "\n",
      " dec_res_post_attn.zarr keys: ['x']\n",
      "  x shape (4, 12, 128, 768) chunks (1, 1, 128, 768) dtype float16\n",
      "\n",
      " dec_res_post_mlp.zarr keys: ['x']\n",
      "  x shape (4, 12, 128, 768) chunks (1, 1, 128, 768) dtype float16\n",
      "\n",
      " dec_res_pre_attn.zarr keys: ['x']\n",
      "  x shape (4, 12, 128, 768) chunks (1, 1, 128, 768) dtype float16\n",
      "\n",
      " dec_self_attn.zarr keys: ['attn']\n",
      "  attn shape (4, 12, 12, 128, 128) chunks (1, 1, 1, 128, 128) dtype float16\n",
      "\n",
      " dec_self_qkv.zarr keys: ['k', 'q', 'v']\n",
      "  k shape (4, 12, 12, 128, 64) chunks (1, 1, 1, 128, 64) dtype float16\n",
      "  q shape (4, 12, 12, 128, 64) chunks (1, 1, 1, 128, 64) dtype float16\n",
      "  v shape (4, 12, 12, 128, 64) chunks (1, 1, 1, 128, 64) dtype float16\n"
     ]
    }
   ],
   "source": [
    "def describe_store(p: Path):\n",
    "    root = zarr.open(str(p), mode=\"r\")\n",
    "    if hasattr(root, \"array_keys\"):\n",
    "        keys = list(root.array_keys())\n",
    "        print(\"\\n\", p.name, \"keys:\", keys)\n",
    "        for k in keys:\n",
    "            a = root[k]\n",
    "            print(\" \", k, \"shape\", a.shape, \"chunks\", a.chunks, \"dtype\", a.dtype)\n",
    "    else:\n",
    "        print(\"\\n\", p.name, \"array shape\", root.shape, \"chunks\", root.chunks, \"dtype\", root.dtype)\n",
    "\n",
    "for p in zarr_paths:\n",
    "    describe_store(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8165fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec_hidden.zarr h slice (0, 0, slice(0, 3, None), slice(0, 8, None)) -> (3, 8) float16\n",
      "min/mean/max: -0.25537109375 -0.047393798828125 0.10443115234375\n",
      "dec_res_pre_attn.zarr x slice (0, 0, slice(0, 3, None), slice(0, 8, None)) -> (3, 8) float16\n",
      "min/mean/max: -0.25537109375 -0.047393798828125 0.10443115234375\n",
      "dec_self_attn.zarr attn slice (0, 0, 0, slice(0, 3, None), slice(0, 6, None)) -> (3, 6) float16\n",
      "min/mean/max: 0.0 0.010009765625 0.03125\n"
     ]
    }
   ],
   "source": [
    "def zarr_slice(p: Path, key: str, slc):\n",
    "    root = zarr.open(str(p), mode=\"r\")\n",
    "    arr = root[key]\n",
    "    x = np.asarray(arr[slc])\n",
    "    print(p.name, key, \"slice\", slc, \"->\", x.shape, x.dtype)\n",
    "    print(\"min/mean/max:\", float(np.min(x)), float(np.mean(x)), float(np.max(x)))\n",
    "\n",
    "zarr_slice(run_dir / \"dec_hidden.zarr\", \"h\", (0, 0, slice(0, 3), slice(0, 8)))\n",
    "zarr_slice(run_dir / \"dec_res_pre_attn.zarr\", \"x\", (0, 0, slice(0, 3), slice(0, 8)))\n",
    "zarr_slice(run_dir / \"dec_self_attn.zarr\", \"attn\", (0, 0, 0, slice(0, 3), slice(0, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb08959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active span: 108 → 127\n",
      "tokens: ['Q' ':' 'ĠWhere' 'Ġare' 'Ġ' 'Ġyou' 'Ġlikely' 'Ġto' 'Ġfind' 'Ġa' 'Ġhamb'\n",
      " 'urger' '?' 'Ċ' 'Cho' 'ices' ':' 'Ċ' 'A' ':']\n"
     ]
    }
   ],
   "source": [
    "mask = df.loc[i, \"attention_mask\"]\n",
    "ids = df.loc[i, \"input_ids\"]\n",
    "toks = df.loc[i, \"tokens\"]\n",
    "\n",
    "idx = np.where(mask == 1)[0]\n",
    "print(\"active span:\", idx[0], \"→\", idx[-1])\n",
    "print(\"tokens:\", toks[idx[0]:idx[-1]+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce30df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c327e9",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ddc2f1",
   "metadata": {},
   "source": [
    "tokenizer examination of trace lengths on raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f9e33",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d648490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\venvs\\Masters_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1221 bad prompts: 0\n",
      "prompt token lengths percentiles: {50: 46, 75: 51, 90: 57, 95: 60, 97: 63, 99: 69, 100: 97}\n",
      "question+header lengths percentiles: {50: 21, 75: 25, 90: 30, 95: 34, 97: 37, 99: 43, 100: 72}\n",
      "choices+Answer lengths percentiles: {50: 25, 75: 27, 90: 29, 95: 30, 97: 30, 99: 32, 100: 34}\n",
      "exceed 128: 0 (0.0%)\n",
      "exceed 256: 0 (0.0%)\n",
      "exceed 384: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "ds = load_dataset(\"commonsense_qa\", split=\"validation\")\n",
    "\n",
    "LABELS = [\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "\n",
    "def build_prompt(ex):\n",
    "    q = ex[\"question\"]\n",
    "    labs = ex[\"choices\"][\"label\"]\n",
    "    txts = ex[\"choices\"][\"text\"]\n",
    "    choices = \"\\n\".join([f\"{l}: {t}\" for l, t in zip(labs, txts)])\n",
    "    return f\"Q: {q}\\nChoices:\\n{choices}\\nAnswer:\"\n",
    "\n",
    "lens = []\n",
    "lens_q = []\n",
    "lens_choices = []\n",
    "lens_prompt = []\n",
    "\n",
    "bad = 0\n",
    "for ex in ds:\n",
    "    prompt = build_prompt(ex)\n",
    "\n",
    "    ids_prompt = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "    ids_q = tokenizer(\"Q: \" + ex[\"question\"] + \"\\nChoices:\\n\", add_special_tokens=False)[\"input_ids\"]\n",
    "    ids_choices = tokenizer(\"\\n\".join([f\"{l}: {t}\" for l, t in zip(ex[\"choices\"][\"label\"], ex[\"choices\"][\"text\"])]) + \"\\nAnswer:\", add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "    Lp = len(ids_prompt)\n",
    "    Lq = len(ids_q)\n",
    "    Lc = len(ids_choices)\n",
    "\n",
    "    lens.append(Lp)\n",
    "    lens_q.append(Lq)\n",
    "    lens_choices.append(Lc)\n",
    "    lens_prompt.append(Lp)\n",
    "\n",
    "    if Lp < 10:\n",
    "        bad += 1\n",
    "\n",
    "lens = np.array(lens)\n",
    "lens_q = np.array(lens_q)\n",
    "lens_choices = np.array(lens_choices)\n",
    "\n",
    "def pct(arr):\n",
    "    return {p: int(np.percentile(arr, p)) for p in [50, 75, 90, 95, 97, 99, 100]}\n",
    "\n",
    "print(\"N:\", len(ds), \"bad prompts:\", bad)\n",
    "print(\"prompt token lengths percentiles:\", pct(lens))\n",
    "print(\"question+header lengths percentiles:\", pct(lens_q))\n",
    "print(\"choices+Answer lengths percentiles:\", pct(lens_choices))\n",
    "\n",
    "too_128 = int((lens > 128).sum())\n",
    "too_256 = int((lens > 256).sum())\n",
    "too_384 = int((lens > 384).sum())\n",
    "print(\"exceed 128:\", too_128, f\"({too_128/len(lens)*100:.1f}%)\")\n",
    "print(\"exceed 256:\", too_256, f\"({too_256/len(lens)*100:.1f}%)\")\n",
    "print(\"exceed 384:\", too_384, f\"({too_384/len(lens)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "975288e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOP 0 idx 979 prompt_len 97 id 5efadabaf61b5174916e3ab659bcd283 ---\n",
      "Q: Danny found that the carpet did not ,match the drapes, which was disappointing, because this place was expensive.  But it was the only place in town that wasn't booked solid for the week and he needed it while he was in town, so he couldn't complain.   Where might this place be?\n",
      "Choices:\n",
      "A: brothel\n",
      "B: restaurant\n",
      "C: building\n",
      "D: bowling alley\n",
      "E: at hotel\n",
      "Answer:\n",
      "\n",
      "--- TOP 1 idx 628 prompt_len 82 id 41bab71fea3fa04e5a4e10a2f86996df ---\n",
      "Q: The architect thought that a mezzanine would look good, but the planning committee rejected it.  They told the architect that they felt it was a potential hazard given the ages of the people who would be using it.  What might they be designing?\n",
      "Choices:\n",
      "A: actors\n",
      "B: theater\n",
      "C: concert hall\n",
      "D: floors\n",
      "E: school\n",
      "Answer:\n",
      "\n",
      "--- TOP 2 idx 316 prompt_len 81 id d867f76d000bdb59b9b4cb982bd7f0a0 ---\n",
      "Q: Joe was thrown from his boat into the water.  The water was cold because it was the middle of winter and he cried out to his crew for help.  They couldn't hear him over the sound of the what?\n",
      "Choices:\n",
      "A: surface of earth\n",
      "B: teardrops\n",
      "C: snowflake\n",
      "D: typhoon\n",
      "E: motor\n",
      "Answer:\n",
      "\n",
      "--- TOP 3 idx 382 prompt_len 78 id 27f2074270ea8a5e8f5ec2a017ec4a50 ---\n",
      "Q: Dan was a farmer with just one heifer.  But that was okay, he only kept her for milk, and he didn't think he'd find good farmland in a place as cold as where?\n",
      "Choices:\n",
      "A: arizona\n",
      "B: farm yard\n",
      "C: michigan\n",
      "D: german field\n",
      "E: dairy farm\n",
      "Answer:\n",
      "\n",
      "--- TOP 4 idx 80 prompt_len 75 id 60e92cd2f35c345872d1a898e1718d55 ---\n",
      "Q: George didn't have a car, but he still had his two feet.   His socks were smelly and his soles were blistered, but that didn't matter.  He could still do what?\n",
      "Choices:\n",
      "A: michigan\n",
      "B: walk\n",
      "C: stay still\n",
      "D: stink\n",
      "E: hands\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "idx_sorted = np.argsort(-lens)\n",
    "for k in range(5):\n",
    "    i = int(idx_sorted[k])\n",
    "    ex = ds[i]\n",
    "    prompt = build_prompt(ex)\n",
    "    print(\"\\n--- TOP\", k, \"idx\", i, \"prompt_len\", int(lens[i]), \"id\", ex[\"id\"], \"---\")\n",
    "    print(prompt[:600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bc5930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max_len 128 options visible counts: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1221}\n",
      "\n",
      "max_len 256 options visible counts: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1221}\n"
     ]
    }
   ],
   "source": [
    "def count_options_in_prefix(prompt, max_len):\n",
    "    ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"][:max_len]\n",
    "    txt = tokenizer.decode(ids)\n",
    "    return sum([f\"\\n{l}:\" in txt or f\"{l}:\" in txt for l in LABELS]), txt\n",
    "\n",
    "for max_len in [128, 256]:\n",
    "    counts = []\n",
    "    for ex in ds:\n",
    "        prompt = build_prompt(ex)\n",
    "        c, _ = count_options_in_prefix(prompt, max_len)\n",
    "        counts.append(c)\n",
    "    counts = np.array(counts)\n",
    "    print(\"\\nmax_len\", max_len, \"options visible counts:\",\n",
    "          {v: int((counts==v).sum()) for v in range(0,6)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13e076b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active span: 97 -> 127 len: 31\n",
      "Q: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Choices:\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "mask = df.loc[i, \"attention_mask\"]\n",
    "ids = df.loc[i, \"input_ids\"]\n",
    "idx = np.where(mask == 1)[0]\n",
    "active_ids = ids[idx[0]:idx[-1]+1].tolist()\n",
    "print(\"active span:\", int(idx[0]), \"->\", int(idx[-1]), \"len:\", len(active_ids))\n",
    "print(tokenizer.decode(active_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c72b5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.ndarray'> len: 0 value: []\n",
      "1 <class 'numpy.ndarray'> len: 0 value: []\n",
      "2 <class 'numpy.ndarray'> len: 0 value: []\n",
      "3 <class 'numpy.ndarray'> len: 0 value: []\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    v = df.loc[i, \"csqa_choices\"]\n",
    "    print(i, type(v), \"len:\", (len(v) if hasattr(v, \"__len__\") else None), \"value:\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17815dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters_env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
